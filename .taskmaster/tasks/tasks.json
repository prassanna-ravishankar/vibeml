{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Implement Data Model Classes and Validation Layer",
        "description": "Create Pydantic models for TrainingRequest, JobHandle, JobStatus, CostEstimate, and WorkflowMetadata to provide type-safe data structures and request validation throughout the system.",
        "details": "Create src/vibeml/models.py with Pydantic v2 models: TrainingRequest (model, dataset, workflow, gpu_type, cloud, max_cost, hyperparameters), JobHandle (job_id, cluster_name, status, cost_estimate, created_at, model, dataset), JobStatus enum (PENDING, RUNNING, COMPLETED, FAILED, TERMINATED), CostEstimate (hourly_rate, estimated_duration_hours, min_cost, max_cost, expected_cost, currency), WorkflowMetadata (name, description, gpu_requirements, typical_duration_hours, cost_range_usd, supported_model_sizes). Update existing server.py to use these models for request validation and response formatting. Add comprehensive field validation (model format checking, dataset existence, GPU type validation, cost limits).",
        "testStrategy": "Unit tests for each model with valid/invalid data, field validation tests, edge cases (empty strings, negative numbers, invalid enum values), serialization/deserialization tests.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Expand Exception Hierarchy with Custom Error Types",
        "description": "Extend the existing exception hierarchy to add missing exception types and implement error recovery strategies and translation mechanisms for better user experience.",
        "details": "Add to src/vibeml/exceptions.py: ConfigurationError (invalid config settings), BudgetExceededError (cost limits), CloudProviderError (cloud-specific failures), ModelNotFoundError (invalid model IDs), DatasetError (dataset access issues). Implement error recovery strategies: retry with exponential backoff for transient failures, fallback suggestions for capacity issues, automatic region switching for unavailable resources. Create error translation layer that converts technical SkyPilot/cloud errors into user-friendly messages with actionable guidance. Add error context preservation to maintain debugging information while showing clean user messages.",
        "testStrategy": "Test exception creation and inheritance, error message formatting, recovery strategy triggers, error translation accuracy, context preservation in error chains.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Implement Configuration Management System",
        "description": "Create a comprehensive configuration management system for credentials, user preferences, budget controls, and secure storage with encryption for sensitive data.",
        "details": "Create src/vibeml/config/ module with: credentials.py (encrypted storage using cryptography library, credential retrieval, cloud provider credential validation), preferences.py (user defaults for GPU types, regions, budget limits, workflow preferences stored in ~/.vibeml/config.json), budget.py (budget enforcement, spending tracking, cost alerts, approval workflows for exceeding limits). Implement secure credential storage using Fernet encryption, environment variable fallbacks, credential validation against cloud provider APIs. Add configuration file versioning and migration support. Include configuration validation and schema checking.",
        "testStrategy": "Test credential encryption/decryption, config file I/O, default value handling, budget enforcement logic, credential validation, migration between config versions.",
        "priority": "high",
        "dependencies": [
          2
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Implement Advanced Parameter Validation and Resource Configuration",
        "description": "Create robust parameter validation that checks model existence on HuggingFace, dataset accessibility, GPU memory requirements, and resource constraint validation.",
        "details": "Create src/vibeml/tasks/validation.py with HuggingFace Hub integration using huggingface_hub library to validate model existence and access permissions. Implement dataset validation including format checking and access verification. Add GPU memory requirement calculation based on model size and batch size. Create resource constraint validation ensuring GPU type matches model requirements. Implement src/vibeml/tasks/resources.py for advanced resource configuration: automatic GPU selection based on model size, multi-region fallback configuration, spot instance vs on-demand decision logic, disk size optimization based on model and dataset size. Add cost optimization suggestions and resource utilization monitoring.",
        "testStrategy": "Test model validation with valid/invalid HuggingFace models, dataset access verification, GPU memory calculations for various model sizes, resource optimization logic, fallback region selection.",
        "priority": "medium",
        "dependencies": [
          1,
          2
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Implement Advanced Script Generation and Template System",
        "description": "Create a sophisticated script generation system that produces optimized training scripts with error handling, checkpointing, and monitoring capabilities.",
        "details": "Create src/vibeml/tasks/scripts.py with Jinja2 template engine for generating Python training scripts. Implement template system for different workflows with parameter substitution, conditional logic for different model sizes/types, optimized hyperparameter selection based on model and GPU type. Add comprehensive error handling in generated scripts: CUDA out of memory recovery, checkpoint resumption, dataset loading error handling, model loading failures. Implement automatic checkpointing strategy with configurable intervals, checkpoint validation, and resumption logic. Add training progress monitoring with loss tracking, time estimation, and resource utilization reporting. Include integration with Weights & Biases for experiment tracking (optional).",
        "testStrategy": "Test script generation for various model/dataset combinations, validate Python syntax of generated scripts, test error handling scenarios, checkpoint save/load functionality, progress monitoring accuracy.",
        "priority": "medium",
        "dependencies": [
          1,
          4
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Implement Cloud Integration Layer with Cost Estimation",
        "description": "Create a comprehensive cloud integration layer that wraps SkyPilot operations with async support, cost estimation, and Nebius-specific optimizations.",
        "details": "Create src/vibeml/cloud/ module with: skypilot_wrapper.py (async wrappers around sky.launch(), sky.status(), sky.down() using asyncio.run_in_executor, proper timeout handling, error propagation), cost_estimator.py (real-time pricing API integration for Nebius, cost calculation with spot discounts, duration estimation based on model size and dataset, cost alerts and budget checking), nebius.py (Nebius-specific configuration, region optimization, instance type mapping, authentication handling), error_translator.py (translate SkyPilot exceptions to user-friendly messages, suggest alternatives for common failures, provide actionable guidance). Implement automatic retry logic for transient failures, spot instance preemption handling, and capacity issue fallbacks.",
        "testStrategy": "Test async SkyPilot operations, cost estimation accuracy, Nebius configuration mapping, error translation quality, retry mechanisms, timeout handling.",
        "priority": "high",
        "dependencies": [
          2,
          3
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Implement Enhanced Task Generation with Multiple Workflows",
        "description": "Enhance the existing task generation system to support additional workflows, better parameter handling, and optimized resource allocation.",
        "details": "Enhance src/vibeml/tasks.py to support additional workflows: standard LoRA fine-tuning (without Unsloth), full parameter fine-tuning with DeepSpeed/FSDP, custom script workflows, distributed training setups. Implement intelligent resource allocation: automatic GPU count calculation based on model size, memory-optimized configurations, network bandwidth requirements for multi-node setups. Add workflow-specific optimizations: quantization settings for different GPU types, batch size optimization, gradient accumulation strategies, learning rate scheduling. Integrate with the validation and script generation systems for comprehensive task creation. Add support for custom Docker images and environment configurations.",
        "testStrategy": "Test task generation for all supported workflows, validate resource allocation logic, test script integration, verify GPU optimization for different model sizes, test distributed training configurations.",
        "priority": "medium",
        "dependencies": [
          4,
          5
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Implement Workflow Registry and Selection System",
        "description": "Create a sophisticated workflow management system that can recommend optimal workflows based on user requirements and constraints.",
        "details": "Create src/vibeml/workflows/ module with: registry.py (workflow registration with metadata, capability tracking, compatibility matrices), selector.py (intelligent workflow selection based on model size, budget constraints, quality requirements, time constraints using scoring algorithms), metadata.py (comprehensive workflow metadata including cost ranges, typical durations, GPU requirements, quality trade-offs). Implement workflow recommendation engine that considers: model size vs GPU memory, budget vs quality trade-offs, time constraints vs training thoroughness, user experience level. Add workflow comparison features and decision explanation. Support for custom workflow plugins and third-party integrations.",
        "testStrategy": "Test workflow registration, selection algorithm accuracy, metadata completeness, recommendation quality for various constraints, plugin system functionality.",
        "priority": "medium",
        "dependencies": [
          1,
          7
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Implement Comprehensive Job Management System",
        "description": "Create a complete job lifecycle management system with advanced tracking, monitoring, and control capabilities.",
        "details": "Create src/vibeml/jobs/ module with: launcher.py (job launching with pre-flight checks, budget validation, resource verification), tracker.py (real-time status monitoring, progress tracking from logs, resource utilization monitoring), terminator.py (graceful job termination, checkpoint preservation, cleanup management), logs.py (log streaming, parsing, filtering, structured log extraction). Implement job state machine with proper transitions, job queuing for resource constraints, automatic failover for spot instance preemptions. Add job metadata tracking, cost accumulation, progress estimation, and completion notifications. Include integration with monitoring services and alerting systems.",
        "testStrategy": "Test complete job lifecycle, state transitions, monitoring accuracy, log parsing, failover mechanisms, cost tracking precision, notification delivery.",
        "priority": "high",
        "dependencies": [
          6,
          8
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Implement Enhanced MCP Server with Request/Response Handling",
        "description": "Enhance the existing FastMCP server implementation with proper request validation, response formatting, and comprehensive tool coverage.",
        "details": "Create src/vibeml/server/ module with: validators.py (Pydantic-based request validation, parameter type checking, constraint validation), formatters.py (MCP-compliant response formatting, error serialization, structured data output), mcp_server.py (enhanced FastMCP server with all tools, async request handling, proper error propagation). Implement comprehensive tool coverage: enhanced launch_training with full parameter support, detailed get_training_status with progress metrics, advanced stop_training with cleanup options, cost estimation with real-time pricing, workflow recommendation, job management tools. Add request middleware for authentication, rate limiting, and logging. Implement response caching for expensive operations.",
        "testStrategy": "Test all MCP tools with various input combinations, request validation accuracy, response format compliance, error handling quality, async operation reliability, middleware functionality.",
        "priority": "high",
        "dependencies": [
          1,
          9
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "Implement Advanced Error Handling and Recovery System",
        "description": "Create a comprehensive error handling system with automatic recovery, user guidance, and detailed error reporting.",
        "details": "Enhance src/vibeml/exceptions.py with: error classification system (transient, permanent, user-actionable), automatic recovery strategies (retry with backoff, fallback options, alternative suggestions), error context preservation and reporting. Implement error recovery patterns: spot instance preemption handling with automatic relaunch, quota exceeded handling with region suggestions, model loading failures with alternative model recommendations, dataset access issues with format conversion suggestions. Add error reporting dashboard, error pattern analysis, and proactive issue prevention. Include integration with logging and monitoring systems for error tracking and analysis.",
        "testStrategy": "Test error classification accuracy, recovery strategy effectiveness, error reporting completeness, recovery success rates, user guidance quality, error pattern detection.",
        "priority": "medium",
        "dependencies": [
          2,
          9
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Implement Comprehensive Integration Testing Framework",
        "description": "Create extensive integration tests that cover end-to-end workflows, real cloud operations, and system reliability testing.",
        "details": "Create comprehensive test suite in tests/ with: integration tests for complete workflow execution from MCP request to job completion, cloud integration tests with real Nebius launches (using test/dev accounts), error scenario testing with fault injection, performance testing for concurrent operations, load testing for multiple simultaneous jobs. Implement test fixtures for common scenarios, mock services for expensive operations, test data management for reproducible testing. Add continuous integration setup with automated testing, test coverage reporting, and performance benchmarking. Include stress testing for resource limits and failure scenarios.",
        "testStrategy": "Comprehensive end-to-end testing covering all user journeys, real cloud operations validation, error scenario coverage, performance benchmarks, stress testing results.",
        "priority": "medium",
        "dependencies": [
          10,
          11
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 13,
        "title": "Implement CLI Enhancement and Documentation System",
        "description": "Enhance the existing CLI with additional commands, configuration management, and comprehensive documentation generation.",
        "details": "Enhance src/vibeml/__main__.py with additional CLI commands: config management (credential setup, preference configuration), job management (list, status, stop), workflow operations (list, describe, estimate-cost), debugging utilities (validate-config, test-connection). Implement interactive configuration wizard for first-time setup, credential validation, and cloud provider authentication. Add comprehensive help system with examples, troubleshooting guides, and best practices. Create auto-generated documentation from code docstrings, configuration schemas, and usage examples. Include man page generation and shell completion support.",
        "testStrategy": "Test all CLI commands, interactive wizard functionality, help system accuracy, documentation generation, shell completion, cross-platform compatibility.",
        "priority": "low",
        "dependencies": [
          3,
          10
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 14,
        "title": "Implement Production Deployment and Monitoring Features",
        "description": "Add production-ready features including monitoring, logging, metrics collection, and deployment utilities for the VibeML system.",
        "details": "Implement production features: structured logging with configurable levels, metrics collection using Prometheus-style metrics, health check endpoints, graceful shutdown handling, configuration validation on startup. Add monitoring dashboard for job statistics, cost tracking, system health, error rates. Implement deployment utilities: Docker containerization, Kubernetes manifests, cloud deployment scripts, configuration management for different environments. Add security features: API key management, request authentication, rate limiting, audit logging. Include backup and recovery procedures for job data and configurations.",
        "testStrategy": "Test monitoring accuracy, logging completeness, metrics collection, deployment scripts, security features, backup/recovery procedures, production load handling.",
        "priority": "low",
        "dependencies": [
          12,
          13
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 15,
        "title": "Integrate Material MkDocs Documentation Platform",
        "description": "Stand up a MkDocs-based documentation system using the Material theme, migrate existing content into a best-practice information architecture, and automate publication to GitHub Pages and Read the Docs with quality checks in pre-commit.",
        "details": "- Add MkDocs tooling: update `pyproject.toml` docs extras (and `docs/requirements.txt`) to include `mkdocs`, `mkdocs-material`, `mkdocstrings[python]`, `mkdocs-section-index`, and `mkdocs-awesome-pages-plugin`; keep Sphinx pins only if still needed elsewhere.\n- Author a top-level `mkdocs.yml` configuring site metadata, `nav` for Get Started → Internals taxonomy, Material palette with light/dark toggle, navigation tabs, instant loading, code-copy buttons, and the required plugins (mkdocstrings handler pointed at `src/`).\n- Restructure `docs/`: migrate existing Sphinx Markdown (`docs/index.md`, `docs/usage.md`, etc.) into MkDocs pages under folders like `docs/get-started/`, `docs/concepts/`, `docs/how-to/`, `docs/reference/`, `docs/internals/`, and `docs/playbooks/`; add tutorials demonstrating real workflows that call the CLI (`src/vibeml/__main__.py`) and scripts module (`src/vibeml/scripts/generator.py`).\n- Configure `mkdocstrings` sections to auto-render Pydantic models from `src/vibeml/models.py`, job orchestration code (`src/vibeml/cloud/cost_estimator.py`, `src/vibeml/tasks.py`), and MCP interfaces (`src/vibeml/server.py`), including handler options for dataclasses/pydantic summaries and cross-reference anchors.\n- Add reference content for CLI commands and MCP endpoints by embedding code snippets and `:::` directives, leveraging Material’s content tabs to show CLI vs. Python usage examples.\n- Create `.github/workflows/docs.yml` that installs docs deps, runs `mkdocs build --strict`, and deploys to GitHub Pages via `actions/deploy-pages`; add environment protection steps (e.g., caching, concurrency) and conditionals for tagged releases vs. main branch.\n- Provide Read the Docs compatibility: add `readthedocs.yml` targeting MkDocs, referencing `docs/requirements.txt`, and enabling preview build artifacts.\n- Extend `.pre-commit-config.yaml` with MkDocs validation (local hook running `mkdocs build --strict --config-file mkdocs.yml`), Markdown linting, broken-link checking, and YAML formatting for nav files; ensure hook ordering avoids redundant installs.\n- Update `README.md` to describe the new documentation workflow, local preview instructions (`mkdocs serve`), and links to published docs.",
        "testStrategy": "- Run `uv pip install -r docs/requirements.txt` (or `pip install`) and execute `mkdocs build --strict` locally to confirm the nav, plugins, and mkdocstrings resolve without warnings.\n- Start `mkdocs serve` and spot-check Get Started, Concepts, and Reference sections for correct Material features (tabs, instant navigation, copy buttons) and accurate API auto-generation for `TrainingRequest` and related models.\n- Execute `pre-commit run --all-files` to ensure documentation hooks and linting pass.\n- Trigger the new GitHub Actions workflow via `act` or dry run review to verify build + deploy stages, and confirm Read the Docs configuration by running `readthedocs-build` locally or reviewing its YAML for correctness.",
        "status": "in-progress",
        "dependencies": [
          1
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Update documentation dependency manifests",
            "description": "Review and modify doc-related dependencies to support Material MkDocs.",
            "dependencies": [],
            "details": "Update `pyproject.toml` extras and `docs/requirements.txt` to include MkDocs Material stack while retaining Sphinx pins only if required elsewhere.",
            "status": "done",
            "testStrategy": "Run `uv pip install -r docs/requirements.txt` to verify dependency resolution succeeds."
          },
          {
            "id": 2,
            "title": "Author comprehensive mkdocs.yml configuration",
            "description": "Create a Material-themed MkDocs configuration covering site metadata and navigation.",
            "dependencies": [
              1
            ],
            "details": "Write `mkdocs.yml` with site metadata, Material theme options, navigation taxonomy, required plugins, and mkdocstrings handlers pointing at project modules.\n<info added on 2025-10-26T21:30:34.533Z>\nLooking at the mkdocs.yml file that was created, I can see the comprehensive configuration is complete and functional.Successfully implemented mkdocs.yml configuration file at project root with all requested features. The configuration includes Material theme with automatic light/dark mode switching, comprehensive navigation structure organized into logical sections (Get Started → Concepts → How-to → Reference → Internals → Playbooks), and mkdocstrings integration properly configured for Python docstring parsing using Google style. Added extensive markdown extensions including Mermaid diagram support, tabbed content, code highlighting with copy buttons, and admonitions. Configured mike versioning provider for multi-version documentation support. Navigation tabs are enabled with sticky positioning and instant loading for improved user experience. All plugin configurations are optimized for the project's Python codebase structure with source path pointing to src/ directory.\n</info added on 2025-10-26T21:30:34.533Z>",
            "status": "done",
            "testStrategy": "Execute `mkdocs build --strict` to ensure the configuration loads without errors."
          },
          {
            "id": 3,
            "title": "Restructure docs content into MkDocs IA",
            "description": "Migrate existing Markdown into the new folder structure with tutorials and references.",
            "dependencies": [
              2
            ],
            "details": "Organize `docs/` into Get Started, Concepts, How-To, Reference, Internals, and Playbooks sections while adding CLI and script tutorials plus mkdocstrings reference pages.",
            "status": "done",
            "testStrategy": "Preview via `mkdocs serve` and verify each navigation section renders expected content."
          },
          {
            "id": 4,
            "title": "Set up documentation automation workflows",
            "description": "Implement GitHub Pages and Read the Docs automation for the MkDocs site.",
            "dependencies": [
              3
            ],
            "details": "Create `.github/workflows/docs.yml` for strict builds and deploys, add caching and branch conditions, and author `readthedocs.yml` referencing docs requirements with preview builds enabled.",
            "status": "done",
            "testStrategy": "Trigger workflow locally with `act` or dry-run checks; confirm RTD config passes validation using `readthedocs-build` if available."
          },
          {
            "id": 5,
            "title": "Enhance pre-commit hooks for docs quality gates",
            "description": "Integrate MkDocs, Markdown linting, link checking, and YAML formatting into pre-commit.",
            "dependencies": [
              2,
              3
            ],
            "details": "Extend `.pre-commit-config.yaml` with hooks for `mkdocs build --strict`, markdown linting, link validation, and YAML formatting while ordering hooks to avoid redundant installs.",
            "status": "done",
            "testStrategy": "Run `pre-commit run --all-files` to ensure new hooks execute successfully."
          },
          {
            "id": 6,
            "title": "Update README with MkDocs workflow guidance",
            "description": "Document the new docs workflow, preview tooling, and publication targets.",
            "dependencies": [
              3,
              4,
              5
            ],
            "details": "Revise `README.md` to explain MkDocs usage, local preview commands, and links to GitHub Pages and Read the Docs outputs, including contribution tips.",
            "status": "done",
            "testStrategy": "Manually review the rendered README (e.g., GitHub preview) to ensure clarity and correct links."
          }
        ]
      },
      {
        "id": 16,
        "title": "Implement Durable Job Persistence Layer",
        "description": "Persist VibeML training jobs across MCP server restarts by introducing a durable storage layer and wiring it into the FastMCP runtime.",
        "details": "• Add a `src/vibeml/persistence/` package with a `jobs_repository.py` module that maps the existing `JobHandle` schema (see src/vibeml/models.py) to a SQLite-backed store. Use a single-writer pattern with WAL mode, `sqlite3` or SQLAlchemy/SQLModel metadata, and a lightweight `JobRecord` Pydantic model to serialize datetimes, enum values, and the `metadata` blob.\n• Initialize the repository during server startup (hydrate in `src/vibeml/server.py:31`) so that persisted jobs repopulate `ACTIVE_CLUSTERS`, and expose async-safe CRUD helpers (`save_job`, `update_status`, `list_active`, `purge_completed`). Wrap blocking DB work in `asyncio.to_thread` or adopt `aiosqlite` to keep the FastMCP event loop responsive.\n• Replace direct dictionary writes in `launch_training` and `get_training_status` (`src/vibeml/server.py:70-150`) with persistence calls. Ensure status updates, cost estimates, and termination paths call `update_status` and keep `ACTIVE_CLUSTERS` in sync with the durable state.\n• Store the database file under the existing preferences directory (reuse `PreferencesManager` from `src/vibeml/config/preferences.py` so paths remain user-configurable) and document rotation/backups via structured logging hooks already introduced in Task 14.\n• Add migration/bootstrap logic (CREATE TABLE IF NOT EXISTS, PRAGMA schema version) and defensive error handling using the `SkyPilotError` / `ValidationError` patterns from `src/vibeml/exceptions.py` so persistence failures surface actionable guidance.",
        "testStrategy": "• Unit-test the repository with an in-memory SQLite URL or tmp path to assert `save_job`, `get_job`, and `update_status` round-trip a `JobHandle` while retaining enum values and metadata.\n• Add an async test that exercises `launch_training` with SkyPilot mocked, verifies the repository captures the new job record, and that reloading the server module hydrates `ACTIVE_CLUSTERS` from disk.\n• Simulate concurrent status updates (async tasks calling `update_status`) to ensure locking prevents race conditions and persisted state remains consistent.\n• Smoke-test restart resilience by persisting a job, re-importing `src.vibeml.server`, and confirming downstream APIs (`get_training_status`, `terminate_job` if available) operate on the restored record.",
        "status": "done",
        "dependencies": [
          3,
          9
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Design durable job persistence architecture",
            "description": "Map out the SQLite-backed job repository and schema structure for durable storage.",
            "dependencies": [],
            "details": "Document table schema, JobRecord fields, WAL configuration, and single-writer pattern choices aligned with JobHandle requirements.",
            "status": "done",
            "testStrategy": null
          },
          {
            "id": 2,
            "title": "Implement SQLite jobs repository module",
            "description": "Create the persistence package and build the JobRecord repository with CRUD helpers.",
            "dependencies": [
              1
            ],
            "details": "Add src/vibeml/persistence/jobs_repository.py with JobRecord Pydantic model, sqlite3/SQLModel setup, migration bootstrap, and async-safe wrappers.",
            "status": "done",
            "testStrategy": "Use in-memory SQLite to verify save, fetch, update status, and error handling behaviors."
          },
          {
            "id": 3,
            "title": "Integrate repository into server lifecycle",
            "description": "Initialize and hydrate the repository during FastMCP server startup and shutdown.",
            "dependencies": [
              2
            ],
            "details": "Hook repository into src/vibeml/server.py startup, repopulate ACTIVE_CLUSTERS from persisted jobs, ensure preferences path handling, and manage graceful teardown.",
            "status": "done",
            "testStrategy": "Add startup sequence test using a temporary DB to ensure ACTIVE_CLUSTERS gets repopulated."
          },
          {
            "id": 4,
            "title": "Refactor job launch and status flows to persist state",
            "description": "Replace in-memory job dictionary writes with repository operations in server logic.",
            "dependencies": [
              3
            ],
            "details": "Update launch_training, get_training_status, termination paths to call repository save/update helpers, maintain ACTIVE_CLUSTERS sync, and propagate SkyPilotError/ValidationError handling.",
            "status": "done",
            "testStrategy": "Mock repository in async tests to confirm status updates and termination paths persist correctly."
          },
          {
            "id": 5,
            "title": "Add persistence-focused tests and logging hooks",
            "description": "Cover repository operations and persistence-aware job flows with automated tests and logging.",
            "dependencies": [
              2,
              4
            ],
            "details": "Implement unit/integration tests for persistence, ensure structured logging documents rotation/backups, and validate metadata serialization across job lifecycle.",
            "status": "done",
            "testStrategy": "Combine repository unit tests and async integration test invoking launch_training with mocked dependencies."
          }
        ]
      },
      {
        "id": 17,
        "title": "Re-architect MCP Layer Around Native SkyPilot State",
        "description": "Rewrite the product requirements and refactor the MCP server to drop the custom job persistence in favour of SkyPilot’s built-in job state and APIs.",
        "details": "- Rewrite the PRD/architecture narrative in `docs/concepts/architecture.md` (and adjust `mkdocs.yml` nav if needed) so it specifies that VibeML is a thin MCP wrapper over SkyPilot, highlights `sky.launch`, `sky.status`, `sky.jobs` data sourced from `~/.sky/state.json`, and clarifies lifecycle expectations (launch → SkyPilot-managed state → teardown) with updated diagrams and call flows.\n- Remove the durable storage layer by deleting `src/vibeml/persistence/` and `tests/test_persistence.py`, cleaning up any `JobsRepository` imports, exports, and packaging hooks so no SQLite references remain.\n- Simplify `src/vibeml/server.py` so each MCP tool interacts directly with SkyPilot: keep the executor-based `sky.launch` call, replace `_get_repository`/`ACTIVE_CLUSTERS` lookups with a helper that calls `sky.status(cluster_names=[cluster_id], refresh=True)` and reads SkyPilot’s state JSON for fallbacks, map SkyPilot job states (e.g., `INIT`, `RUNNING`, `SUCCEEDED`, `FAILED`, `STOPPED`) to `JobStatus`, and ensure `stop_training` / `list_active_training_jobs` emit data sourced from the SkyPilot API instead of any local cache.\n- Update `src/vibeml/models.py` (and any serializers) so `JobHandle` is populated from SkyPilot status rows/handles rather than persisted DB records, including adding a status mapping layer and optional metadata drawn from `sky.jobs` (e.g., submission time, resources, cost fields when available).\n- Refresh docs and task guidance that referenced a bespoke job tracker—e.g., edit `docs/get-started/installation.md`, `docs/get-started/quickstart.md`, `docs/playbooks/index.md`, and `docs/how-to/use-mcp.md` to instruct users to rely on `sky status`, `sky logs`, and the SkyPilot state file, and document the MCP ↔ SkyPilot integration contract (request schemas, polling strategy, teardown) in `docs/reference/mcp.md`.\n- Add/adjust automated coverage so new SkyPilot integration paths are exercised: create async unit tests (e.g., `tests/test_server_status.py`) that monkeypatch `sky.launch`, `sky.status`, and `sky.down` to return realistic objects/DataFrames, verifying status translation and error handling without any SQLite fixtures.",
        "testStrategy": "- Add unit tests for the new SkyPilot adapters/server helpers (`pytest tests/test_server_status.py`) to confirm state translation, error propagation, and teardown behaviour, and remove the obsolete persistence test module.\n- Run `nox -s tests` (or `pytest`) and `nox -s mypy` to ensure the refactor keeps type-checking and existing suites passing.\n- Lint the touched code with `ruff check src/vibeml tests` to confirm imports and async helpers remain clean.\n- Build the docs with `mkdocs build --strict` to validate the rewritten PRD, navigation updates, and new integration guidance render without warnings.",
        "status": "pending",
        "dependencies": [
          16
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Rewrite architecture narrative for SkyPilot MCP integration",
            "description": "Revise architecture documentation to emphasize SkyPilot-backed MCP lifecycle and interactions.",
            "dependencies": [],
            "details": "Update docs/concepts/architecture.md with SkyPilot-focused overview, adjust diagrams and mkdocs.yml navigation to reflect the new architecture storyline.",
            "status": "done",
            "testStrategy": "Build docs (e.g., `mkdocs build`) to confirm navigation and links remain valid."
          },
          {
            "id": 2,
            "title": "Remove legacy persistence package and tests",
            "description": "Eliminate obsolete SQLite-backed persistence modules and clean related references.",
            "dependencies": [],
            "details": "Delete src/vibeml/persistence/ and tests/test_persistence.py, scrub JobsRepository imports/usages, and ensure packaging metadata no longer exposes persistence code.",
            "status": "done",
            "testStrategy": "Search for leftover persistence references (`rg \"JobsRepository\"`) and run lint/tests to catch missing imports."
          },
          {
            "id": 3,
            "title": "Refactor MCP server to source state from SkyPilot APIs",
            "description": "Rewrite server tools to call SkyPilot for job lifecycle data instead of local stores.",
            "dependencies": [
              2
            ],
            "details": "Simplify src/vibeml/server.py by wiring tool handlers to sky.launch/sky.status/sky.jobs, add helpers for state JSON fallbacks, and map SkyPilot job states to internal JobStatus values.",
            "status": "done",
            "testStrategy": "Execute relevant server unit tests (once updated) and perform smoke runs of key MCP tool paths."
          },
          {
            "id": 4,
            "title": "Adapt JobHandle modelling for SkyPilot-derived data",
            "description": "Update JobHandle and related serializers to consume SkyPilot job metadata.",
            "dependencies": [
              3
            ],
            "details": "Modify src/vibeml/models.py to populate JobHandle from SkyPilot status rows, add state-mapping utilities, and support optional metadata fields surfaced by sky.jobs.\n<info added on 2025-10-27T00:06:16.243Z>\nI'll analyze the codebase to understand the current implementation and provide an accurate update for this subtask.Based on my analysis of the codebase, I can see that the user is correct. The current implementation in `src/vibeml/server.py` already handles the mapping from SkyPilot cluster status to VibeML JobStatus using the `_map_sky_status_to_job_status()` function on lines 29-40. The `JobHandle` model in `src/vibeml/models.py` (lines 155-176) is indeed a simple DTO that works perfectly as-is for both server responses and can be populated from SkyPilot cluster information when needed.\n\nThe server refactoring (subtask 17.3) has already implemented the necessary status mapping logic, and the `JobHandle` model doesn't require any structural changes to work with SkyPilot-derived data.\n\nAnalysis confirms that JobHandle model (src/vibeml/models.py:155-176) requires no modifications. The existing DTO structure with job_id, cluster_name, status, cost_estimate, created_at, model, dataset, workflow, gpu_type, and metadata fields works perfectly for both MCP server responses and SkyPilot cluster data population. The server.py refactoring in subtask 17.3 already provides the necessary status mapping via _map_sky_status_to_job_status() function. The JobHandle can be instantiated directly from SkyPilot cluster information without any schema changes. Task complete - no model modifications needed.\n</info added on 2025-10-27T00:06:16.243Z>",
            "status": "done",
            "testStrategy": "Run type checks and unit tests covering JobHandle serialization to ensure new mappings behave correctly."
          },
          {
            "id": 5,
            "title": "Refresh user-facing docs for SkyPilot-based workflows",
            "description": "Update guidance docs to instruct users on relying on SkyPilot tooling and state.",
            "dependencies": [
              1,
              3,
              4
            ],
            "details": "Edit docs/get-started/installation.md, docs/get-started/quickstart.md, docs/playbooks/index.md, docs/how-to/use-mcp.md, and docs/reference/mcp.md to document the MCP ↔ SkyPilot contract, CLI usage, and lifecycle expectations.",
            "status": "pending",
            "testStrategy": "Rebuild docs (`mkdocs build`) and spot-check updated sections for accuracy and cross-links."
          },
          {
            "id": 6,
            "title": "Add async tests for SkyPilot-backed MCP server flows",
            "description": "Implement new tests that monkeypatch SkyPilot APIs to validate server behaviour.",
            "dependencies": [
              3,
              4
            ],
            "details": "Create async pytest modules (e.g., tests/test_server_status.py) that mock sky.launch/status/down responses to exercise status translation, error handling, and teardown paths.",
            "status": "pending",
            "testStrategy": "Run `pytest tests/test_server_status.py` to verify the new asynchronous tests pass and cover key scenarios."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-10-26T20:40:28.632Z",
      "updated": "2025-10-27T00:06:27.062Z",
      "description": "Tasks for master context"
    }
  }
}